"""
Copy-Paste Augmentation Studio â€” Streamlit Frontend

Requirements (pip):
    streamlit
    pyyaml
    pillow

Optional (better YAML editing but not required):
    ruamel.yaml

Run:
    streamlit run app.py

Notes:
- This app does NOT implement the augmentation logic; it calls your provided Python
  function: main(work_dir, output_folder_name, config_filename).
- Set the "Augmentor entry point" to a fully-qualified import path where `main` lives,
  e.g. `my_pkg.copypaste.entry:main` or `my_pkg.copypaste.entry` (we'll resolve `main`).
- Progress is estimated by counting new files in the output dataset folder while the
  job runs. If your backend exposes richer progress, you can wire it in easily.
"""

from __future__ import annotations
import os
import io
import re
import sys
import time
import json
import glob
import uuid
import shutil
import types
import queue
import base64
import threading
import importlib
from dataclasses import dataclass, asdict
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any

import streamlit as st
import yaml
from PIL import Image, ImageDraw

# =============================
# --------- SETTINGS ----------
# =============================
# You can change these defaults in the UI Settings panel
DEFAULT_RULES_DIR = str(Path.cwd() / "rules")
DEFAULT_MATERIALS_DIR = str(Path.cwd() / "materials")
DEFAULT_OUTPUTS_DIR = str(Path.cwd() / "datasets")
DEFAULT_HISTORY_PATH = str(Path.cwd() / "history.jsonl")
DEFAULT_AUGMENTOR_ENTRY = "your_package.copypaste.entry:main"  # edit in UI

# =============================
# ---------- MODELS -----------
# =============================
@dataclass
class MaterialSet:
    class_name: str
    folder: str
    created_at: str
    updated_at: str
    sample_count: int

@dataclass
class BuildRecord:
    run_id: str
    dataset_name: str
    background_dir: str
    material_sets: List[str]  # list of class names or folders
    rule_file: str
    created_at: str
    params: Dict[str, Any]
    output_dir: str

# =============================
# ------- PERSISTENCE ---------
# =============================
class HistoryStore:
    def __init__(self, path: str):
        self.path = Path(path)
        self.path.parent.mkdir(parents=True, exist_ok=True)
        self._fh = None

    def append(self, rec: BuildRecord):
        with self.path.open("a", encoding="utf-8") as f:
            f.write(json.dumps(asdict(rec), ensure_ascii=False) + "\n")

    def read_all(self) -> List[BuildRecord]:
        if not self.path.exists():
            return []
        recs = []
        with self.path.open("r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    d = json.loads(line)
                    recs.append(BuildRecord(**d))
                except Exception:
                    continue
        # Sort newest first
        recs.sort(key=lambda r: r.created_at, reverse=True)
        return recs

# =============================
# --------- UTILITIES ---------
# =============================

def now_str() -> str:
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def ensure_dir(p: str | Path) -> Path:
    p = Path(p)
    p.mkdir(parents=True, exist_ok=True)
    return p


def list_images(folder: str | Path) -> List[Path]:
    exts = ["*.jpg", "*.jpeg", "*.png", "*.bmp", "*.tif", "*.tiff", "*.webp"]
    files: List[Path] = []
    for e in exts:
        files.extend(Path(folder).glob(e))
    return sorted(files)


def load_yaml_text(path: Path) -> str:
    try:
        return path.read_text(encoding="utf-8")
    except UnicodeDecodeError:
        return path.read_text(encoding="gbk", errors="replace")


def validate_yaml(content: str) -> Tuple[bool, Optional[str]]:
    try:
        _ = yaml.safe_load(content) if content.strip() else {}
        return True, None
    except Exception as e:
        return False, str(e)


def save_text(path: Path, content: str):
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(content, encoding="utf-8")


def count_files(folder: Path) -> int:
    if not folder.exists():
        return 0
    return sum(1 for _ in folder.rglob("*.*"))


def resolve_main(entry: str):
    """Resolve an entry string to a callable.
    Accepted formats:
        - "pkg.module.submod:main"
        - "pkg.module.submod" (must expose attr `main`)
    Returns the `main` callable.
    """
    fn_name = None
    mod_path = entry
    if ":" in entry:
        mod_path, fn_name = entry.split(":", 1)
    mod = importlib.import_module(mod_path)
    fn = getattr(mod, fn_name or "main")
    if not callable(fn):
        raise RuntimeError(f"Resolved object is not callable: {entry}")
    return fn


# =============================
# ------- STATE & CACHE -------
# =============================
if "settings" not in st.session_state:
    st.session_state.settings = {
        "rules_dir": DEFAULT_RULES_DIR,
        "materials_dir": DEFAULT_MATERIALS_DIR,
        "outputs_dir": DEFAULT_OUTPUTS_DIR,
        "history_path": DEFAULT_HISTORY_PATH,
        "augmentor_entry": DEFAULT_AUGMENTOR_ENTRY,
    }

if "busy" not in st.session_state:
    st.session_state.busy = False

if "progress" not in st.session_state:
    st.session_state.progress = 0.0

if "running_thread" not in st.session_state:
    st.session_state.running_thread = None

# =============================
# ------------ UI -------------
# =============================
st.set_page_config(page_title="Copy-Paste Augmentation Studio", layout="wide")
st.title("ğŸ§© Copy-Paste Augmentation Studio")

with st.expander("âš™ï¸ Settings", expanded=False):
    cols = st.columns(2)
    with cols[0]:
        st.session_state.settings["rules_dir"] = st.text_input(
            "Rules directory", st.session_state.settings["rules_dir"]
        )
        st.session_state.settings["materials_dir"] = st.text_input(
            "Materials root directory", st.session_state.settings["materials_dir"]
        )
        st.session_state.settings["outputs_dir"] = st.text_input(
            "Datasets output root", st.session_state.settings["outputs_dir"]
        )
    with cols[1]:
        st.session_state.settings["history_path"] = st.text_input(
            "History JSONL path", st.session_state.settings["history_path"]
        )
        st.session_state.settings["augmentor_entry"] = st.text_input(
            "Augmentor entry point (module[:func])",
            st.session_state.settings["augmentor_entry"],
            help="Import path resolving to a callable main(work_dir, output_folder_name, config_filename)",
        )

# Init persistence
RULES_DIR = ensure_dir(st.session_state.settings["rules_dir"])  # type: ignore
MATERIALS_DIR = ensure_dir(st.session_state.settings["materials_dir"])  # type: ignore
OUTPUTS_DIR = ensure_dir(st.session_state.settings["outputs_dir"])  # type: ignore
HISTORY = HistoryStore(st.session_state.settings["history_path"])  # type: ignore

# =============== TAB LAYOUT ===============

rules_tab, mats_tab, build_tab, gallery_tab = st.tabs([
    "ğŸ“œ è´´å›¾è§„åˆ™ç®¡ç†",
    "ğŸ—‚ï¸ è´´å›¾ç´ æé›†ç®¡ç†",
    "ğŸ­ æ ·æœ¬ç”Ÿäº§ï¼ˆå·¥ä½œæµï¼‰",
    "ğŸ–¼ï¸ ç”»å»Š",
])

# -----------------------------------------
# 1) è´´å›¾è§„åˆ™ç®¡ç†
# -----------------------------------------
with rules_tab:
    st.subheader("ğŸ“œ è´´å›¾è§„åˆ™ç®¡ç†")
    left, right = st.columns([1, 2])

    # List existing YAML files
    with left:
        st.caption("è§„åˆ™æ–‡ä»¶ï¼ˆ.yaml / .ymlï¼‰")
        yaml_files = sorted(list(RULES_DIR.glob("*.y*ml")))
        names = [f.name for f in yaml_files]
        selected_name = st.selectbox("é€‰æ‹©è§„åˆ™æ–‡ä»¶", options=["<æ–°å»º>"] + names)

        if selected_name == "<æ–°å»º>":
            new_name = st.text_input("æ–°å»ºè§„åˆ™æ–‡ä»¶åï¼ˆå«æ‰©å±•å .yamlï¼‰", "rule_example.yaml")
            if st.button("åˆ›å»ºç©ºç™½è§„åˆ™æ–‡ä»¶"):
                target = RULES_DIR / new_name
                if target.exists():
                    st.warning("å·²æœ‰åŒåæ–‡ä»¶ã€‚")
                else:
                    template = (
                        "# ç¤ºä¾‹æ¨¡æ¿\n"
                        "plasticbag:\n  - D:/è´´å›¾æ ·æœ¬é›†/cropped_objects/class_0\n\n"
                        "number:\n  plasticbag: [1, 3]\n\n"
                        "rules:\n  plasticbag:\n    size:\n      reference: _\n      rule: mean\n      scale: [0.03, 0.04]\n    position:\n      reference: _\n      value: [0.40, 0.05, 0.55, 0.95]\n"
                    )
                    save_text(target, template)
                    st.success(f"å·²åˆ›å»º {target}")
                    st.experimental_rerun()
        else:
            st.info(f"å½“å‰æ–‡ä»¶ï¼š{selected_name}")
            # Rename / delete helpers
            new_basename = st.text_input("é‡å‘½åä¸º", selected_name)
            c1, c2 = st.columns(2)
            with c1:
                if st.button("é‡å‘½å") and new_basename != selected_name:
                    src = RULES_DIR / selected_name
                    dst = RULES_DIR / new_basename
                    if dst.exists():
                        st.error("ç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ã€‚")
                    else:
                        src.rename(dst)
                        st.success("å·²é‡å‘½åã€‚")
                        st.experimental_rerun()
            with c2:
                if st.button("åˆ é™¤æ­¤è§„åˆ™æ–‡ä»¶", type="secondary"):
                    (RULES_DIR / selected_name).unlink(missing_ok=True)
                    st.success("å·²åˆ é™¤ã€‚")
                    st.experimental_rerun()

    # Editor
    with right:
        if selected_name == "<æ–°å»º>":
            st.caption("ï¼ˆæ–°å»ºæ¨¡å¼ï¼‰åœ¨å·¦ä¾§åˆ›å»ºæ–‡ä»¶åå†è¿›è¡Œç¼–è¾‘ã€‚")
        else:
            target = RULES_DIR / selected_name
            content = load_yaml_text(target)
            text = st.text_area("ç¼–è¾‘ YAML è§„åˆ™", value=content, height=420)
            valid, err = validate_yaml(text)
            if valid:
                st.success("YAML è¯­æ³•æ ¡éªŒé€šè¿‡ã€‚")
            else:
                st.error(f"YAML è¯­æ³•é”™è¯¯ï¼š{err}")
            c1, c2 = st.columns(2)
            with c1:
                if st.button("ä¿å­˜ä¿®æ”¹", disabled=not valid):
                    save_text(target, text)
                    st.toast("å·²ä¿å­˜ã€‚", icon="âœ…")
            with c2:
                st.download_button("ä¸‹è½½æ­¤è§„åˆ™æ–‡ä»¶", data=text, file_name=selected_name, mime="text/yaml")

# -----------------------------------------
# 2) è´´å›¾ç´ æé›†ç®¡ç†
# -----------------------------------------
with mats_tab:
    st.subheader("ğŸ—‚ï¸ è´´å›¾ç´ æé›†ç®¡ç†")

    # Register an existing folder as a material set
    with st.expander("ğŸ“ ç»‘å®šç°æœ‰æ–‡ä»¶å¤¹ä¸ºç´ æé›†", expanded=True):
        class_name = st.text_input("ç´ æé›†ç±»å (e.g., plasticbag)")
        folder_path = st.text_input("ç´ æé›†æ–‡ä»¶å¤¹è·¯å¾„", value=str(MATERIALS_DIR / "plasticbag"))
        if st.button("ç»‘å®šä¸ºç´ æé›†"):
            if not class_name:
                st.error("è¯·è¾“å…¥ç±»åã€‚")
            else:
                folder = ensure_dir(folder_path)
                # Count samples
                sc = len(list_images(folder))
                meta = MaterialSet(
                    class_name=class_name,
                    folder=str(folder),
                    created_at=now_str(),
                    updated_at=now_str(),
                    sample_count=sc,
                )
                # Write a metadata file under the folder
                (folder / "_material_meta.json").write_text(
                    json.dumps(asdict(meta), ensure_ascii=False, indent=2), encoding="utf-8"
                )
                st.success(f"å·²ç»‘å®šï¼š{class_name} -> {folder}")

    # Uploader to add images into a class folder
    with st.expander("ğŸ“¤ å‘ç´ æé›†ä¸­æ–°å¢å›¾ç‰‡", expanded=False):
        # discover known sets
        known_sets = []
        for p in MATERIALS_DIR.rglob("_material_meta.json"):
            try:
                d = json.loads(p.read_text(encoding="utf-8"))
                known_sets.append((d["class_name"], Path(d["folder"])) )
            except Exception:
                pass
        if not known_sets:
            st.info("å°šæœªç»‘å®šä»»ä½•ç´ æé›†ã€‚è¯·å…ˆåœ¨ä¸Šé¢ç»‘å®šã€‚")
        else:
            choices = [f"{cn}  â€”  {fp}" for cn, fp in known_sets]
            sel = st.selectbox("é€‰æ‹©ç´ æé›†", options=choices)
            files = st.file_uploader("é€‰æ‹©å›¾ç‰‡ (å¯å¤šé€‰)", type=["png", "jpg", "jpeg", "bmp", "tif", "tiff", "webp"], accept_multiple_files=True)
            if st.button("ä¸Šä¼ åˆ°ç´ æé›†") and files:
                idx = choices.index(sel)
                cn, fp = known_sets[idx]
                saved = 0
                for f in files:
                    suffix = Path(f.name).suffix or ".jpg"
                    out = fp / f"{uuid.uuid4().hex}{suffix}"
                    out.write_bytes(f.read())
                    saved += 1
                # update meta
                meta_path = fp / "_material_meta.json"
                d = json.loads(meta_path.read_text(encoding="utf-8"))
                d["updated_at"] = now_str()
                d["sample_count"] = len(list_images(fp))
                meta_path.write_text(json.dumps(d, ensure_ascii=False, indent=2), encoding="utf-8")
                st.success(f"å·²ä¿å­˜ {saved} å¼ å›¾ç‰‡åˆ° {cn}")

    # Overview table
    with st.expander("ğŸ“Š ç´ æé›†ä¸€è§ˆ", expanded=True):
        rows = []
        for meta in MATERIALS_DIR.rglob("_material_meta.json"):
            try:
                d = json.loads(meta.read_text(encoding="utf-8"))
                rows.append(d)
            except Exception:
                continue
        if rows:
            st.dataframe(rows, use_container_width=True)
        else:
            st.info("æš‚æ— ç´ æé›†ã€‚")

# -----------------------------------------
# 3) æ ·æœ¬ç”Ÿäº§ï¼ˆä¸»è¦å·¥ä½œæµï¼‰
# -----------------------------------------
with build_tab:
    st.subheader("ğŸ­ æ ·æœ¬ç”Ÿäº§ï¼ˆä¸»è¦å·¥ä½œæµï¼‰")

    c1, c2 = st.columns(2)
    with c1:
        dataset_name = st.text_input("æ„é€ çš„æ•°æ®é›†åç§°", value=f"ds_{datetime.now().strftime('%m%d_%H%M')}")
        background_dir = st.text_input("èƒŒæ™¯å›¾æ‰€åœ¨ç›®å½• (work_dir)", value=str(Path.cwd() / "backgrounds"))
        rule_file = st.text_input("è´´å›¾è§„åˆ™æ–‡ä»¶ (.yaml)", value=str((RULES_DIR / "rule_example.yaml")))
        per_bg_count = st.number_input("æ¯å¼ èƒŒæ™¯å›¾ç”Ÿæˆçš„æ ·æœ¬æ•°é‡", min_value=1, max_value=50, value=3)
        extra_params = st.text_area("å…¶ä»–å‚æ•° (JSONï¼Œå¯ç•™ç©º)", value="{}")
    with c2:
        st.caption("é€‰æ‹©/ç¡®è®¤ç´ æé›†ï¼ˆä½œä¸ºè¯´æ˜å­˜æ¡£ï¼Œåç«¯æŒ‰è§„åˆ™æ–‡ä»¶æŸ¥æ‰¾ï¼‰")
        # show known sets for user's reference
        known_sets = []
        for meta in MATERIALS_DIR.rglob("_material_meta.json"):
            try:
                d = json.loads(meta.read_text(encoding="utf-8"))
                known_sets.append(d)
            except Exception:
                pass
        mat_labels = [f"{d['class_name']} ({d['sample_count']})" for d in known_sets]
        selected_idx = st.multiselect("ç´ æé›†ï¼ˆå¤šé€‰ä»…ç”¨äºè®°å½•ï¼‰", options=list(range(len(known_sets))), format_func=lambda i: mat_labels[i])
        selected_sets = [known_sets[i]["class_name"] for i in selected_idx]
        output_dir = ensure_dir(OUTPUTS_DIR / dataset_name)
        st.info(f"è¾“å‡ºç›®å½•ï¼š{output_dir}")

    # Run controller
    run_button = st.button("ğŸš€ åˆæˆ (è°ƒç”¨åç«¯)", disabled=st.session_state.busy)

    def run_job():
        st.session_state.busy = True
        try:
            # Resolve entry
            entry = st.session_state.settings["augmentor_entry"]
            fn = resolve_main(entry)

            # Prepare params
            params = json.loads(extra_params or "{}")
            params.update({
                "work_dir": background_dir,
                "output_folder_name": str(output_dir),
                "config_filename": rule_file,
                # If your backend supports per_bg_count as an arg, you can include it here too
                # e.g., "per_bg_count": per_bg_count
            })

            # Estimate total expected files using background count * per_bg_count
            bg_imgs = list_images(background_dir)
            expected = max(1, len(bg_imgs) * int(per_bg_count))

            # Start a watcher thread to update progress by counting images under output_dir
            stop_flag = threading.Event()

            def watcher():
                last = 0
                while not stop_flag.is_set():
                    cur = len(list_images(output_dir))
                    last = cur
                    st.session_state.progress = min(0.99, cur / max(1, expected))
                    time.sleep(1)

            wt = threading.Thread(target=watcher, daemon=True)
            wt.start()

            # Call backend
            fn(**params)  # blocking call until finished

            stop_flag.set()
            wt.join(timeout=2)
            st.session_state.progress = 1.0

            # Save history record
            rec = BuildRecord(
                run_id=uuid.uuid4().hex,
                dataset_name=dataset_name,
                background_dir=background_dir,
                material_sets=selected_sets,
                rule_file=rule_file,
                created_at=now_str(),
                params={"per_bg_count": per_bg_count, **json.loads(extra_params or "{}")},
                output_dir=str(output_dir),
            )
            HISTORY.append(rec)
            st.success("åˆæˆå®Œæˆå¹¶å·²å†™å…¥å†å²è®°å½•ã€‚")
        except Exception as e:
            st.error(f"è¿è¡Œå¤±è´¥ï¼š{e}")
        finally:
            st.session_state.busy = False

    if run_button and not st.session_state.busy:
        threading.Thread(target=run_job, daemon=True).start()

    st.progress(st.session_state.progress)

    # History table
    st.markdown("---")
    st.subheader("ğŸ“š å†å²è®°å½•")
    recs = HISTORY.read_all()
    if recs:
        rows = [asdict(r) for r in recs]
        st.dataframe(rows, use_container_width=True)
    else:
        st.info("æš‚æ— å†å²è®°å½•ã€‚")

# -----------------------------------------
# 4) ç”»å»Š
# -----------------------------------------
with gallery_tab:
    st.subheader("ğŸ–¼ï¸ ç”»å»Šï¼šæŸ¥çœ‹å†å²æ•°æ®é›†")

    recs = HISTORY.read_all()
    if not recs:
        st.info("è¿˜æ²¡æœ‰æ„å»ºè¿‡æ•°æ®é›†ã€‚è¯·å…ˆå»æ‰§è¡Œä¸€æ¬¡åˆæˆä»»åŠ¡ã€‚")
    else:
        names = [f"{r.dataset_name}  â€”  {r.created_at}" for r in recs]
        idx = st.selectbox("é€‰æ‹©ä¸€ä¸ªæ•°æ®é›†", options=list(range(len(recs))), format_func=lambda i: names[i])
        rec = recs[idx]

        # Preview controls
        show_overlays = st.checkbox("å åŠ æ ‡æ³¨ï¼ˆè‡ªåŠ¨è¯†åˆ« YOLO bbox/seg æ ¼å¼ï¼‰", value=True)
        cols = st.columns([1, 1])

        out_dir = Path(rec.output_dir)
        aug_imgs = list_images(out_dir)
        if not aug_imgs:
            st.warning("è¯¥æ•°æ®é›†çš„è¾“å‡ºç›®å½•ä¸­æœªæ‰¾åˆ°å›¾ç‰‡ã€‚")
        else:
            # Simple pager
            i = st.number_input("ç´¢å¼•", min_value=0, max_value=len(aug_imgs)-1, value=0)
            img_path = aug_imgs[i]

            with cols[0]:
                st.caption("åˆæˆç»“æœï¼ˆå³ä¾§å¯æ˜¾ç¤ºå åŠ æ ‡æ³¨ï¼‰")
                st.image(str(img_path), use_column_width=True)

            with cols[1]:
                if show_overlays:
                    st.caption("åˆæˆç»“æœ + æ ‡æ³¨å åŠ ")
                    st.image(overlay_annotations(img_path), use_column_width=True)
                else:
                    st.caption("ä»…æ˜¾ç¤ºå›¾ç‰‡")
                    st.image(str(img_path), use_column_width=True)

            st.write(f"è·¯å¾„ï¼š{img_path}")
            st.write(f"èƒŒæ™¯ç›®å½•ï¼š{rec.background_dir}")
            st.write(f"è§„åˆ™ï¼š{rec.rule_file}")

# =============================
# --- Annotation Overlay ------
# =============================

def overlay_annotations(img_path: Path | str) -> Image.Image:
    """Try to overlay YOLO-style labels if present.

    We try several common patterns:
    - labels/<stem>.txt or same_dir/<stem>.txt
      Each line either:
        * bbox: cls cx cy w h  (normalized)
        * seg:  cls x1 y1 x2 y2 ... (normalized polygon)
    """
    img_path = Path(img_path)
    img = Image.open(img_path).convert("RGB")
    W, H = img.size
    draw = ImageDraw.Draw(img, "RGBA")

    cand = [
        img_path.with_suffix(".txt"),
        img_path.parent / "labels" / (img_path.stem + ".txt"),
    ]
    label_path = None
    for c in cand:
        if c.exists():
            label_path = c
            break

    if not label_path:
        return img

    try:
        lines = label_path.read_text(encoding="utf-8").strip().splitlines()
    except Exception:
        return img

    for line in lines:
        parts = line.strip().split()
        if len(parts) < 5:
            continue
        cls = parts[0]
        vals = list(map(float, parts[1:]))
        if len(vals) == 4:
            # bbox cx cy w h (normalized)
            cx, cy, w, h = vals
            x1 = (cx - w / 2.0) * W
            y1 = (cy - h / 2.0) * H
            x2 = (cx + w / 2.0) * W
            y2 = (cy + h / 2.0) * H
            draw.rectangle([x1, y1, x2, y2], outline=(255, 0, 0, 200), width=2)
        elif len(vals) >= 6 and len(vals) % 2 == 0:
            # polygon (x1 y1 x2 y2 ... normalized)
            pts = []
            for j in range(0, len(vals), 2):
                x = vals[j] * W
                y = vals[j + 1] * H
                pts.append((x, y))
            draw.polygon(pts, outline=(0, 255, 0, 200))
        else:
            # not recognized
            continue
    return img

# =============================
# ------------- END -----------
# =============================
